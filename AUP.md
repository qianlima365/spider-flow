SpiderFlow 可接受使用政策（AUP）

目的
- 促进合法、合规、负责任的抓取实践，避免对网站和数据主体造成伤害。

必须遵守
- 尊重目标网站的 ToS、访问政策与 `robots.txt`。
- 仅在合法授权或合法基础上抓取并处理数据。
- 实施速率限制（建议：并发受控、指数退避）、失败重试与友好访问策略。
- 在可能情况下使用公开 API 或数据导出渠道。
- 对包含个人信息的数据实施最小化与安全存储，支持删除与更正请求。

禁止用途（示例）
- 绕过登录、验证码、付费墙、速率限制或其他技术保护措施。
- 抓取受版权或合同保护的内容并进行未授权传播或商业化。
- 获取、出售或滥用个人信息、账号数据或受限资料。
- 进行渗透测试、漏洞扫描、DDoS、凭据填充、流量欺骗或破坏性行为。
- 用于垃圾营销、欺诈、骚扰、监视或其他侵害合法权益的活动。

操作建议
- 将抓取频率控制在对方站点可承受范围；设置合理的 `User-Agent` 与重试策略。
- 使用缓存与增量抓取，避免重复访问造成负载。
- 在法律要求或网站政策规定下，提供联系渠道以便对方请求停止或删除数据。

问答
- 可以绕过验证码吗？不可。
- 网站 `robots.txt` 禁止某路径时怎么办？不得抓取该路径。
- 可以抓取包含个人数据的页面吗？仅在有合法授权或合法基础且采取必要合规措施的前提下。